{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Unit 7 Live Session </center> </h2>\n",
    "<h4> W203 Instructional Team </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Estimation </h4>\n",
    "<center>![title](estimate.gif)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Announcements\n",
    "1. Announcement 1\n",
    "2. Announcement 2\n",
    "3. Announcement 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the tools to be able to take data (e.g. $\\{X_i\\}_{i=1}^n$)  and use it to infer information about the (joint) distribution of the underlying random variable ($X$). \n",
    "\n",
    "Generally this means that we will use the data to calculate point estimates for the parameters of the distribution of of the underlying random variable. In practice we are often most interested in $E(X)$ , $V(X)$ , or $Cov(X,Y)$ etc.\n",
    "\n",
    "There are a number of techniques that you can use to develop a valid estimator for a parameter. These techniques vary in terms the principle used to arrive at the estimator and the strength of the assumptions needed to support it. \n",
    "\n",
    "All of these estimators are statistics meaning they are functions of the data $\\{X_i\\}_{i=1}^n$ \n",
    "\n",
    "Given the multiplicity of valid estimators for a parameter we need a frame work to evaluate them interms of its sampling distribution.\n",
    "\n",
    "Suppose $\\hat{\\theta}_1$ and $\\hat{\\theta}_2$ are two valid estimators for a parameter $\\theta$. We will compare these estimators in terms of two characteristics their sampling distributions.\n",
    "\n",
    "* Bias: $E(\\hat{\\theta}_j - \\theta)$\n",
    "\n",
    "* Variance: $V(\\hat{\\theta}_j)$\n",
    "\n",
    "Bias is the difference between the most likely value of the estimator $\\hat{\\theta}_j$ and $\\theta$. Variance, as we already know, is how spread out the values of the estimator are around its most likely value.\n",
    "\n",
    "As a general (meaning many exceptions exist) guideline\n",
    "\n",
    "* If $E(\\hat{\\theta}_1 - \\theta) = 0 $ and  $E(\\hat{\\theta}_2 - \\theta) > 0 $ then the unbiased estimator $\\theta_1$ is preferred to $\\theta_2$ \n",
    "\n",
    "* If $E(\\hat{\\theta}_1 - \\theta) = E(\\hat{\\theta}_2 - \\theta) = 0 $ then the estimator with the smallest variance is preferred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Discussion of Point Estimation, MOM, and The Method of ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 ** What is point estimation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.2 ** In your own words, describe how the method of moments is used to estimate the unknown parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.3 ** In your own words, describe how the method of ML is used to estimate the unknown parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.4 ** Why do data scientists need to understand likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Warm-up: Optimization in R\n",
    "\n",
    "The method of maximum likelihood requires an optimization routine. For a few very simple probability models, a closed-form solution exists and the MLE can be derived by hand. In most cases, however, hand-derivation will be too tedious, if at all possible, and a numerical computation technique is needed.\n",
    "\n",
    "Numerical computation techniques often require some sort of optimization. For our purpose in this live session, we will focus on the practice of maximizing likelihood functions using R.\n",
    "\n",
    "There are many optimizers in R(), including optimize(), optim(), and optimx().  I will use optimize() which is very simple to use, but only works for one dimension.\n",
    "\n",
    "As always, I encourage you to read the documentation of the functions you are using: [optim](http://stat.ethz.ch/R-manual/R-devel/library/stats/html/optim.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Optomization Example: ** \n",
    "\n",
    "Suppose that a firm's revenue $r$ from selling a product is related to price $p$ as follows:\n",
    "$$ \n",
    "r = - p^2 + p + 2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.1.1 ** Explain how you would use calculus to find the maximizing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.1.2 ** Solve this numerically in *R*, using the *optimize()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 Maximum Likelihood Estimation of Bernoulli Random Variables\n",
    "Suppose that youâ€™ve got a sequence of values $$ {1, 0, 0, 1, 0, 1, 1, 1, 1, 1} $$ which, say, indicates whether a printer jams each day, for the last 10 business days. Business Question: What is the probability ($p$) that the printer jams in any given day?\n",
    "\n",
    "It resembles draws from a Bernoulli disribution. However, even if we want to model this as a Bernoulli distribution, we do not know what the value of the parameter, $p$, is.\n",
    "\n",
    "It resembles draws from a Bernoulli disribution. However, even if we want to model this as a Bernoulli distribution, we do not know what the value of the parameter, $p$, is.\n",
    "\n",
    "Let's review the steps to find the maximum likelihood estimate for $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.1 ** Define your random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.2 ** Write down the likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.3 ** (Optional) take the log of the likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.4 ** Maximize (the log of) likelihood using calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.5 ** Alternately, maximize the likelihood numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 MLE for Poisson Random Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A Poisson process is a simple model that statisticians use to describe how events occur over time.  Imagine that time stretches out on the x-axis, and each event is a single point on this axis.* \n",
    "\n",
    "\n",
    "<center> ![Poisson Time of Arrival.](Poisson_arrvls.png) </center>\n",
    "\n",
    "The key feature of a Poisson process is that it is *memoryless*.  Loosely speaking, the probability that an event occurs in any (differentially small) instant of time is a constant.  It doesn't depend on how long ago the previous event was, nor does it depend on when future events occur.\n",
    "\n",
    "Data scientists might use a Poisson process (or more complex variations) to represent:\n",
    "\n",
    "  - The scoring of goals in a world cup match\n",
    "  - The arrival of packets to an internet router\n",
    "  - The arrival of customers to a website\n",
    "  - The failure of servers in a cluster\n",
    "  - The time between large meteors hitting the Earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand a Poisson process, imagine an experiment in which you observe the arrival of cars at an intersection.  Assume that the probability density that a car arrives in a differentially small interval of time is just a constant.  The intersection is no more busy during the day than during the night.  \n",
    "\n",
    "Moreover, the probability density that a car arrives at a particular instant does not depend on when the previous cars arrived, not when future cars are going to arrive.  Each moment of time is independent.  This is an example of what we call a memory-less process.\n",
    "\n",
    "Next, suppose we use a camera to record the intersection for a particular length of time, and we write down the number of cars that arrive in that interval.  This is what we call a Poisson random variable.  It has a well-known probability mass function, given by,\n",
    "\n",
    "$$\n",
    "f(x|\\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n",
    "$$\n",
    "\n",
    "Here, $\\lambda$ is a parameter, which represents the mean number of cars in an interval.  (You may take the expectation to check this).  The following graph, \"freely\" borrowed from Wikipedia shows the probability mass function for different values of $\\lambda$.\n",
    "\n",
    "<center>![Poisson Distribution](Poisson_pmf.png) </center>\n",
    "\n",
    "Suppose we take a random sample, and the data appears as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.1 ** Define your random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.2 ** Write down the likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.3 **  Take the log of the likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.4 ** Maximize (the log of) likelihood using calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.5 ** Maximize likelihood numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
